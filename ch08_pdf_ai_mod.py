import streamlit as st
import fitz
from openai import OpenAI
import os
import tempfile
import base64
import shutil
from io import BytesIO
from docx import Document
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ë° base64 ì¸ì½”ë”© (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìˆ˜ì •)
def convert_pdf_to_base64_images(pdf_data):
    document = None
    temp_dir = None
    try:
        document = fitz.open(stream=pdf_data, filetype="pdf")
        images = []
        base64_images = []
        temp_dir = tempfile.mkdtemp()
        
        for page_num in range(len(document)):
            page = document[page_num]
            # DPIë¥¼ ë†’ì—¬ì„œ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ ìƒì„±
            pix = page.get_pixmap(dpi=200)
            
            # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥ (ë¯¸ë¦¬ë³´ê¸°ìš©)
            img_path = os.path.join(temp_dir, f"page_{page_num+1}.png")
            pix.save(img_path)
            images.append(img_path)
            
            # base64 ì¸ì½”ë”© (API ì „ì†¡ìš©)
            img_bytes = pix.tobytes("png")
            base64_img = base64.b64encode(img_bytes).decode('utf-8')
            base64_images.append(base64_img)
            
            # pixmap ë©”ëª¨ë¦¬ í•´ì œ
            pix = None
        
        return images, base64_images
        
    except Exception as e:
        st.error(f"PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], []
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if document:
            document.close()
        # ì„ì‹œ ë””ë ‰í† ë¦¬ëŠ” ë‚˜ì¤‘ì— ì •ë¦¬í•˜ê¸° ìœ„í•´ ë°˜í™˜ëœ images ê²½ë¡œë“¤ê³¼ í•¨ê»˜ ê´€ë¦¬

def cleanup_temp_files(temp_paths):
    """ì„ì‹œ íŒŒì¼ë“¤ì„ ì•ˆì „í•˜ê²Œ ì •ë¦¬"""
    for path in temp_paths:
        try:
            if os.path.exists(path):
                if os.path.isfile(path):
                    os.unlink(path)
                elif os.path.isdir(path):
                    shutil.rmtree(path)
        except Exception as e:
            st.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

def validate_openai_api_key(api_key):
    """OpenAI API í‚¤ ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        client = OpenAI(api_key=api_key)
        # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ í‚¤ ìœ íš¨ì„± ê²€ì‚¬
        response = client.models.list()
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸ (GPT-5 ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬)
        available_models = [model.id for model in response.data]
        
        # GPT-5 ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        gpt5_available = any("gpt-5" in model for model in available_models)
        
        return client, True, None
    except Exception as e:
        error_msg = str(e)
        if "Incorrect API key" in error_msg:
            return None, False, "ì˜ëª»ëœ API í‚¤ì…ë‹ˆë‹¤."
        elif "You exceeded your current quota" in error_msg:
            return None, False, "API ì‚¬ìš© í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤."
        elif "does not exist" in error_msg:
            return None, False, "ì„ íƒí•œ ëª¨ë¸ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            return None, False, f"API í‚¤ ê²€ì¦ ì˜¤ë¥˜: {error_msg}"

def extract_context_for_next_page(content, max_length=800):
    """ë‹¤ìŒ í˜ì´ì§€ë¥¼ ìœ„í•œ ë¬¸ë§¥ ì¶”ì¶œ"""
    if not content:
        return ""
    
    lines = content.split('\n')
    context_lines = []
    current_length = 0
    
    for line in reversed(lines[-10:]):
        line = line.strip()
        if line and current_length + len(line) < max_length:
            context_lines.insert(0, line)
            current_length += len(line) + 1
        elif current_length > 0:
            break
    
    return '\n'.join(context_lines).strip()

def extract_overlap_context(content, max_length=400):
    """í˜ì´ì§€ ê²¹ì¹¨ì„ ìœ„í•œ ë¬¸ë§¥"""
    if not content:
        return "", ""
    
    lines = content.split('\n')
    non_empty_lines = [line.strip() for line in lines if line.strip()]
    
    if not non_empty_lines:
        return "", ""
    
    # ì‹œì‘ ë¶€ë¶„
    start_context = []
    start_length = 0
    for line in non_empty_lines[:5]:
        if start_length + len(line) < max_length:
            start_context.append(line)
            start_length += len(line)
        else:
            break
    
    # ë ë¶€ë¶„
    end_context = []
    end_length = 0
    for line in reversed(non_empty_lines[-5:]):
        if end_length + len(line) < max_length:
            end_context.insert(0, line)
            end_length += len(line)
        else:
            break
    
    return '\n'.join(start_context), '\n'.join(end_context)

# GPT Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„ (ê°œë³„ ì²˜ë¦¬ ë²„ì „) - ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
def analyze_single_image_with_context(client, base64_img, prompt_type, model, max_tokens, image_detail, page_num, total_pages, previous_context="", next_page_start=""):
    if not client or not base64_img:
        return None
        
    if prompt_type == "summary":
        context_info = ""
        if previous_context:
            context_info += f"\n**ì´ì „ í˜ì´ì§€ ë§ˆì§€ë§‰ ë‚´ìš©**:\n{previous_context}\n"
        if next_page_start:
            context_info += f"\n**ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ ë‚´ìš©** (ì°¸ê³ ìš©):\n{next_page_start}\n"
            
        system_prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ {total_pages}í˜ì´ì§€ ì¤‘ {page_num}í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ“‹ **ìš”ì•½ ê·œì¹™:**
- ê°œì¡°ì‹ìœ¼ë¡œ ìš”ì•½ (~ìŒ, ~í–ˆìŒ ì–´ì¡° ì‚¬ìš©)
- í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”
- í‘œë‚˜ ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ ì£¼ìš” ë°ì´í„°ì™€ ìˆ˜ì¹˜ë¥¼ í¬í•¨
- ë¬¸ì„œì˜ ì „ì²´ì ì¸ íë¦„ê³¼ ë§¥ë½ ê³ ë ¤
- ì¤‘ìš”í•œ ê²°ë¡ ì´ë‚˜ ì‹œì‚¬ì  ê°•ì¡°
- í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì˜ ë¨¸ë¦¬ë§, ê¼¬ë¦¬ë§, ë°˜ë³µ ì œëª© ë“±ì€ ì œì™¸
- ìˆ˜í•™ ê³µì‹ì´ë‚˜ ìˆ˜ì‹ì´ í¬í•¨ëœ ê²½ìš° LaTeX í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”
- ë³¸ë¬¸ì—ì„œ ìˆ˜ì‹ ë³€ìˆ˜ë‚˜ ê¸°í˜¸ë¥¼ ì–¸ê¸‰í•  ë•Œë„ LaTeXë¡œ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: "ë³€ìˆ˜ $x$", "$\\beta$ ê³„ìˆ˜")
- ê·¸ë¦¼ì´ë‚˜ ì°¨íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì£¼ìš” ë‚´ìš©ê³¼ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…í•˜ì„¸ìš”

{context_info}

**ì£¼ì˜ì‚¬í•­**: 
- ì´ì „/ë‹¤ìŒ í˜ì´ì§€ì™€ ì—°ê²°ë˜ëŠ” ë‚´ìš©ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”
- í˜ì´ì§€ ì¤‘ê°„ì—ì„œ ëŠì–´ì§„ ë¬¸ì¥ì´ë‚˜ ê°œë…ì´ ìˆë‹¤ë©´ ì™„ì „í•œ ì˜ë¯¸ë¡œ ìš”ì•½í•˜ì„¸ìš”
- ì¤‘ìš”í•œ ë‚´ìš©ì´ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”
- ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§ì— ë‚˜íƒ€ë‚˜ëŠ” ë°˜ë³µì ì¸ ì œëª©ì´ë‚˜ í˜ì´ì§€ ì •ë³´ëŠ” ì œì™¸í•˜ì„¸ìš”"""

    else:  # translation
        context_info = ""
        if previous_context:
            context_info += f"\n**ì´ì „ í˜ì´ì§€ ë§ˆì§€ë§‰ ë‚´ìš©**:\n{previous_context}\n"
        if next_page_start:
            context_info += f"\n**ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ ë‚´ìš©** (ì°¸ê³ ìš©):\n{next_page_start}\n"
            
        system_prompt = f"""ë‹¹ì‹ ì€ ê³ ê¸‰ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. í˜„ì¬ {total_pages}í˜ì´ì§€ ì¤‘ {page_num}í˜ì´ì§€ë¥¼ ë²ˆì—­í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸŒ **ë²ˆì—­ ê·œì¹™:**
1. **ì •í™•ì„±**: ì›ë¬¸ì˜ ì˜ë¯¸ì™€ ë‰˜ì•™ìŠ¤ë¥¼ ì •í™•íˆ ë³´ì¡´
2. **ì „ë¬¸ì„±**: í•™ìˆ ì /ê¸°ìˆ ì  ìš©ì–´ëŠ” ì ì ˆí•œ í•œêµ­ì–´ ì „ë¬¸ ìš©ì–´ ì‚¬ìš©
3. **ìì—°ìŠ¤ëŸ¬ì›€**: í•œêµ­ì–´ ë¬¸ì²´ì™€ ì–´ìˆœì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­
4. **êµ¬ì¡° ë³´ì¡´**: ì›ë¬¸ì˜ ë¬¸ë‹¨ êµ¬ì¡°ì™€ ê°•ì¡°ì  ìœ ì§€
5. **í‘œì™€ ë°ì´í„°**: í‘œëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë²ˆì—­, ìˆ˜ì¹˜ì™€ ë°ì´í„°ëŠ” ì •í™•íˆ ë³´ì¡´
6. **ê·¸ë¦¼ê³¼ ë‹¤ì´ì–´ê·¸ë¨**: ê·¸ë¦¼ ë‚´ í…ìŠ¤íŠ¸ëŠ” ëª¨ë‘ ë²ˆì—­, ê·¸ë¦¼ ìì²´ëŠ” [ê·¸ë¦¼: ê°„ë‹¨í•œ ì„¤ëª…]ìœ¼ë¡œ í‘œí˜„
7. **ì œëª©ê³¼ ì†Œì œëª©**: ì ì ˆí•œ í•œêµ­ì–´ í˜•ì‹ìœ¼ë¡œ ë²ˆì—­
8. **ì°¸ê³ ë¬¸í—Œ**: References, Bibliography ë“±ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì„¹ì…˜ ì œëª©ë§Œ ë²ˆì—­ ê°€ëŠ¥)
9. **ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§**: í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì˜ ë°˜ë³µ ë‚´ìš©ì€ ì œì™¸
10. **ìˆ˜ì‹**: LaTeX í˜•ì‹ìœ¼ë¡œ í‘œí˜„ (ì˜ˆ: $E=mc^2$)
11. **ìˆ˜ì‹ ê¸°í˜¸ ì„¤ëª…**: ë³¸ë¬¸ì—ì„œ ìˆ˜ì‹ì˜ ë³€ìˆ˜ë‚˜ ê¸°í˜¸ë¥¼ ì–¸ê¸‰í•  ë•Œë„ LaTeX ì‚¬ìš© (ì˜ˆ: "ë³€ìˆ˜ $x$ëŠ”", "$\\alpha$ ê³„ìˆ˜", "$\\sigma$ ê°’")
12. **ì¶œë ¥**: ë²ˆì—­ë¬¸ë§Œ ì œê³µ, ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸ ë³‘ê¸° ê¸ˆì§€

{context_info}

**ì¤‘ìš”**: 
- ì´ì „/ë‹¤ìŒ í˜ì´ì§€ì™€ ì—°ê²°ë˜ëŠ” ë¬¸ì¥ì´ë‚˜ ë¬¸ë‹¨ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ ë²ˆì—­í•˜ì„¸ìš”
- í˜ì´ì§€ ì¤‘ê°„ì—ì„œ ëŠì–´ì§„ ë¬¸ì¥ì´ ìˆë‹¤ë©´ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš”
- ëª¨ë“  ë‚´ìš©ì„ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  ì™„ì „íˆ ë²ˆì—­í•˜ì„¸ìš”
- ì°¸ê³ ë¬¸í—Œ ëª©ë¡ì´ í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ë¶€ë¶„ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”
- í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì˜ ë¨¸ë¦¬ë§, ê¼¬ë¦¬ë§, ë°˜ë³µë˜ëŠ” ì œëª© ë“±ì€ ì œì™¸í•˜ê³  ë³¸ë¬¸ë§Œ ë²ˆì—­í•˜ì„¸ìš”
- ì›ë¬¸ì„ ë²ˆì—­ë¬¸ê³¼ í•¨ê»˜ ì œì‹œí•˜ì§€ ë§ê³ , ë²ˆì—­ë¬¸ë§Œ ì œê³µí•˜ì„¸ìš”
- ìˆ˜í•™ ê³µì‹ì´ë‚˜ ìˆ˜ì‹ì€ LaTeX í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”
- ë³¸ë¬¸ì—ì„œ ìˆ˜ì‹ì˜ ë³€ìˆ˜ë‚˜ ê¸°í˜¸ë¥¼ ì„¤ëª…í•  ë•Œë„ LaTeXë¡œ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: "ë³€ìˆ˜ $x$ëŠ”...", "$\\alpha$ê°’ì´...", "$F(x)$ í•¨ìˆ˜ëŠ”...")
- ê·¸ë¦¼ì´ë‚˜ ë‹¤ì´ì–´ê·¸ë¨ì˜ í…ìŠ¤íŠ¸ë§Œ ë²ˆì—­í•˜ê³ , ê·¸ë¦¼ ì„¤ëª…ì€ ê°„ë‹¨íˆ ì¶”ê°€í•˜ì„¸ìš”"""

    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"{system_prompt}\n\nìœ„ ê·œì¹™ì— ë”°ë¼ í˜„ì¬ í˜ì´ì§€ì˜ ì´ë¯¸ì§€ ë‚´ìš©ì„ ì •í™•í•˜ê³  ì™„ì „í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”. ëª¨ë“  í…ìŠ¤íŠ¸, í‘œ, ê·¸ë˜í”„ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  ì²˜ë¦¬í•˜ë˜, í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì˜ ë¨¸ë¦¬ë§ì´ë‚˜ ê¼¬ë¦¬ë§ì€ ì œì™¸í•˜ê³  ë³¸ë¬¸ ë‚´ìš©ë§Œ ì²˜ë¦¬í•˜ì„¸ìš”. ìˆ˜ì‹ê³¼ ë³¸ë¬¸ì˜ ìˆ˜í•™ ê¸°í˜¸ ëª¨ë‘ LaTeX í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”."
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_img}",
                        "detail": image_detail
                    }
                }
            ]
        }
    ]

    try:
        # GPT-5 ëª¨ë¸ ì‚¬ìš© ì‹œ ë” ë†’ì€ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        timeout_seconds = 180 if model.startswith("gpt-5") else 60
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_completion_tokens=max_tokens,
            timeout=timeout_seconds
        )
        
        if response.choices and len(response.choices) > 0:
            choice = response.choices[0]
            if hasattr(choice, 'message') and choice.message and choice.message.content:
                content = choice.message.content.strip()
                if choice.finish_reason == 'length':
                    st.warning(f"âš ï¸ í˜ì´ì§€ {page_num}: ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤.")
                return content
    except Exception as e:
        error_msg = str(e)
        if "timeout" in error_msg.lower():
            st.error(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼: ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif "rate limit" in error_msg.lower():
            st.error(f"í˜ì´ì§€ {page_num} API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.error(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    return None

# ê¸°ì¡´ analyze_single_image í•¨ìˆ˜ (í˜¸í™˜ì„± ìœ ì§€)
def analyze_single_image(client, base64_img, prompt_type, model, max_tokens, image_detail):
    return analyze_single_image_with_context(client, base64_img, prompt_type, model, max_tokens, image_detail, 1, 1, "")

# GPT Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„ - ì—ëŸ¬ ì²˜ë¦¬ ë° ê²€ì¦ ê°œì„ 
def analyze_images_with_gpt(client, base64_images, prompt_type="summary", model="gpt-4o-mini", max_tokens=4000, image_detail="high", process_separately=False):
    
    if not client:
        st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    if not base64_images:
        st.error("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì´ë¯¸ì§€ í¬ê¸° ê²€ì¦
    total_size = 0
    for i, img in enumerate(base64_images):
        img_size = len(img) * 3 / 4  # base64 ë””ì½”ë”© í›„ í¬ê¸° ì¶”ì •
        total_size += img_size
        if img_size > 20 * 1024 * 1024:  # 20MB ì œí•œ
            st.error(f"ì´ë¯¸ì§€ {i+1}ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ ({img_size/1024/1024:.1f}MB). 20MB ì´í•˜ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”.")
            return None
    
    if total_size > 100 * 1024 * 1024:  # ì „ì²´ 100MB ì œí•œ
        st.warning(f"ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°ê°€ í½ë‹ˆë‹¤ ({total_size/1024/1024:.1f}MB). ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ê°œë³„ ì²˜ë¦¬ ëª¨ë“œ
    if process_separately and len(base64_images) > 1:
        st.write(f"ğŸ” {len(base64_images)}ê°œ ì´ë¯¸ì§€ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        results = []
        previous_context = ""
        failed_pages = []
        
        for i, base64_img in enumerate(base64_images):
            st.write(f"ğŸ“„ í˜ì´ì§€ {i+1}/{len(base64_images)} ì²˜ë¦¬ ì¤‘...")
            
            # ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°
            next_page_start = ""
            if i < len(base64_images) - 1:
                try:
                    next_preview = analyze_single_image_with_context(
                        client, base64_images[i+1], prompt_type, model, 1000, "low", 
                        i+2, len(base64_images), "", ""
                    )
                    if next_preview:
                        next_start, _ = extract_overlap_context(next_preview, 300)
                        next_page_start = next_start
                except Exception as e:
                    st.warning(f"ë‹¤ìŒ í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
            
            # ë¬¸ë§¥ì„ í¬í•¨í•œ ê°œë³„ ì²˜ë¦¬
            result = analyze_single_image_with_context(
                client, base64_img, prompt_type, model, max_tokens, image_detail, 
                i+1, len(base64_images), previous_context, next_page_start
            )
            
            if result:
                results.append(result)
                previous_context = extract_context_for_next_page(result, 800)
                st.success(f"âœ… í˜ì´ì§€ {i+1} ì™„ë£Œ")
            else:
                failed_pages.append(i+1)
                results.append(f"âŒ [í˜ì´ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨]")
                previous_context = ""
                st.error(f"âŒ í˜ì´ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨")
        
        if failed_pages:
            st.error(f"ì‹¤íŒ¨í•œ í˜ì´ì§€: {', '.join(map(str, failed_pages))}")
        
        # ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
        final_result = "\n\n".join(results)
        
        # ì „ì²´ ë¬¸ì„œ ë§¥ë½ì—ì„œ ìµœì¢… ì •ë¦¬ (ì‹¤íŒ¨í•œ í˜ì´ì§€ê°€ ì ì€ ê²½ìš°ì—ë§Œ)
        if len(base64_images) > 2 and len(final_result) > 3000 and len(failed_pages) <= len(base64_images) * 0.3:
            st.write("ğŸ”§ ì „ì²´ ë¬¸ì„œ íë¦„ ê°œì„  ì¤‘...")
            try:
                polish_prompt = f"""ë‹¤ìŒì€ í˜ì´ì§€ë³„ë¡œ ê°œë³„ ì²˜ë¦¬ëœ {'ìš”ì•½' if prompt_type == 'summary' else 'ë²ˆì—­'} ê²°ê³¼ì…ë‹ˆë‹¤. 
ì „ì²´ ë¬¸ì„œì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒì„ ê°œì„ í•´ì£¼ì„¸ìš”:

1. í˜ì´ì§€ ê°„ ì—°ê²°ì´ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ë§Œ ë§¤ë„ëŸ½ê²Œ ì—°ê²°
2. ëª…ë°±íˆ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì´ ìˆë‹¤ë©´ ì •ë¦¬
3. ê¸°ì¡´ ë‚´ìš©ì˜ ì˜ë¯¸ë‚˜ ë¶„ëŸ‰ì€ ë³€ê²½í•˜ì§€ ë§ê³ , ì—°ê²°ë¶€ë¶„ë§Œ ê°œì„ 
4. í•˜ë‚˜ì˜ ì—°ì†ëœ ë¬¸ì„œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”
- ì°¸ê³ ë¬¸í—Œì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€
- ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§ ì œê±°: ë°˜ë³µë˜ëŠ” ì±… ì œëª©, ì¥ ì œëª©, í˜ì´ì§€ ë²ˆí˜¸ ë“±ì€ ì •ë¦¬

**ì›ë³¸ ê²°ê³¼:**
{final_result}

**ì¤‘ìš”**: ë‚´ìš©ì„ ì¤„ì´ê±°ë‚˜ ìƒëµí•˜ì§€ ë§ê³ , ë‹¨ì§€ í˜ì´ì§€ ê°„ ì—°ê²°ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¤ì–´ì„œ í•˜ë‚˜ì˜ ë§¤ë„ëŸ¬ìš´ ë¬¸ì„œë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”."""

                polish_response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": polish_prompt}],
                    max_completion_tokens=max_tokens * 2,
                    timeout=240 if model.startswith("gpt-5") else 120
                )
                
                if polish_response.choices and polish_response.choices[0].message.content:
                    polished_result = polish_response.choices[0].message.content.strip()
                    if len(polished_result) > len(final_result) * 0.8:
                        final_result = polished_result
                        st.success("âœ¨ ìµœì¢… ì—°ê²° ê°œì„  ì™„ë£Œ")
                    else:
                        st.warning("ê°œì„  ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ì•„ì„œ ì›ë³¸ ì‚¬ìš©")
                
            except Exception as e:
                st.warning(f"ìµœì¢… ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì›ë³¸ ê²°ê³¼ ì‚¬ìš©): {e}")
        
        return final_result
    
    # ê¸°ì¡´ ì¼ê´„ ì²˜ë¦¬ ëª¨ë“œ
    if prompt_type == "summary":
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•´ì£¼ì„¸ìš”:

ğŸ“‹ **ìš”ì•½ ê·œì¹™:**
- ê°œì¡°ì‹ìœ¼ë¡œ ìš”ì•½ (~ìŒ, ~í–ˆìŒ ì–´ì¡° ì‚¬ìš©)
- í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”
- í‘œë‚˜ ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ ì£¼ìš” ë°ì´í„°ì™€ ìˆ˜ì¹˜ë¥¼ í¬í•¨
- ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ë§¥ë½ê³¼ ë¬¸ì„œ êµ¬ì¡° ê³ ë ¤
- ì¤‘ìš”í•œ ê²°ë¡ ì´ë‚˜ ì‹œì‚¬ì  ê°•ì¡°

ë¬¸ì„œì˜ ëª¨ë“  ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

    else:  # translation
        system_prompt = """ë‹¹ì‹ ì€ ê³ ê¸‰ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ í•œê¸€ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

ğŸŒ **ë²ˆì—­ ê·œì¹™:**
1. **ì •í™•ì„±**: ì›ë¬¸ì˜ ì˜ë¯¸ì™€ ë‰˜ì•™ìŠ¤ë¥¼ ì •í™•íˆ ë³´ì¡´
2. **ì „ë¬¸ì„±**: í•™ìˆ ì /ê¸°ìˆ ì  ìš©ì–´ëŠ” ì ì ˆí•œ í•œêµ­ì–´ ì „ë¬¸ ìš©ì–´ ì‚¬ìš©
3. **ìì—°ìŠ¤ëŸ¬ì›€**: í•œêµ­ì–´ ë¬¸ì²´ì™€ ì–´ìˆœì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­
4. **êµ¬ì¡° ë³´ì¡´**: ì›ë¬¸ì˜ ë¬¸ë‹¨ êµ¬ì¡°ì™€ ê°•ì¡°ì  ìœ ì§€
5. **í‘œì™€ ë°ì´í„°**: í‘œëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë²ˆì—­, ìˆ˜ì¹˜ì™€ ë°ì´í„°ëŠ” ì •í™•íˆ ë³´ì¡´
6. **ê·¸ë¦¼ê³¼ ë‹¤ì´ì–´ê·¸ë¨**: ê·¸ë¦¼ ë‚´ í…ìŠ¤íŠ¸ëŠ” ëª¨ë‘ ë²ˆì—­, ê·¸ë¦¼ ì„¤ëª…ê³¼ ìº¡ì…˜ë„ ë²ˆì—­
7. **ì œëª©ê³¼ ì†Œì œëª©**: ì ì ˆí•œ í•œêµ­ì–´ ì œëª© í˜•ì‹ìœ¼ë¡œ ë²ˆì—­

**ì¤‘ìš”**: ë‹¨ìˆœí•œ ë‹¨ì–´ ì¹˜í™˜ì´ ì•„ë‹Œ, ì˜ë¯¸ì™€ ë§¥ë½ì„ ê³ ë ¤í•œ ê³ í’ˆì§ˆ ì „ë¬¸ ë²ˆì—­ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."""

    st.write(f"ğŸ” {len(base64_images)}ê°œ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬ ì¤‘...")
    
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"{system_prompt}\n\nìœ„ ê·œì¹™ì— ë”°ë¼ ë‹¤ìŒ ì´ë¯¸ì§€ë“¤ì˜ ë‚´ìš©ì„ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”."
                }
            ] + [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_img}",
                        "detail": image_detail
                    }
                } for base64_img in base64_images
            ]
        }
    ]

    try:
        # GPT-5 ëª¨ë¸ ì‚¬ìš© ì‹œ ë” ë†’ì€ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        timeout_seconds = 180 if model.startswith("gpt-5") else 120
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_completion_tokens=max_tokens,
            timeout=timeout_seconds
        )
        
        if response.choices and len(response.choices) > 0:
            choice = response.choices[0]
            
            if hasattr(choice, 'message') and choice.message and choice.message.content:
                content = choice.message.content.strip()
                
                if choice.finish_reason == 'length':
                    st.warning("âš ï¸ ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤. 'í˜ì´ì§€ë³„ ê°œë³„ ì²˜ë¦¬' ì˜µì…˜ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.")
                
                if content:
                    return content
                else:
                    st.error("ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    return None
            else:
                st.error("API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return None
        else:
            st.error("APIì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        error_msg = str(e)
        if "timeout" in error_msg.lower():
            st.error("API ìš”ì²­ ì‹œê°„ ì´ˆê³¼. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
        elif "rate limit" in error_msg.lower():
            st.error("API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.error(f"API ì˜¤ë¥˜: {error_msg}")
        return None

# QMD íŒŒì¼ ì €ì¥ (Quarto Markdown) - ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
def save_to_qmd(filename, **sections):
    """Quarto Markdown íŒŒì¼ë¡œ ì €ì¥"""
    try:
        content_lines = []
        
        # YAML í—¤ë” ì¶”ê°€
        content_lines.append("---")
        content_lines.append("title: \"PDF ë¶„ì„ ê²°ê³¼\"")
        content_lines.append("format: html")
        content_lines.append("editor: visual")
        content_lines.append("---")
        content_lines.append("")
        
        for title, content in sections.items():
            # ì„¹ì…˜ ì œëª© ì¶”ê°€ (ë ˆë²¨ 1 í—¤ë”©)
            content_lines.append(f"# {title}")
            content_lines.append("")
            
            if content and content.strip():
                # ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì¶”ê°€ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìœ ì§€)
                content_lines.append(content)
            else:
                content_lines.append(f"*{title} ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.*")
            
            content_lines.append("")
            content_lines.append("---")
            content_lines.append("")
        
        # ë§ˆì§€ë§‰ êµ¬ë¶„ì„  ì œê±°
        if content_lines and content_lines[-2] == "---":
            content_lines = content_lines[:-2]
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content_lines))
        return True
    except Exception as e:
        st.error(f"QMD íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def save_to_word(filename, **sections):
    try:
        doc = Document()
        
        for title, content in sections.items():
            # ì œëª© ì¶”ê°€
            heading = doc.add_heading(title, level=1)
            
            # ë‚´ìš© í™•ì¸ ë° ì¶”ê°€
            if content and content.strip():
                # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ë˜ ë¹ˆ ì¤„ë„ ìœ ì§€
                lines = content.split('\n')
                
                for line in lines:
                    line_stripped = line.strip()
                    
                    # ë¹ˆ ì¤„ ì²˜ë¦¬
                    if not line_stripped:
                        doc.add_paragraph("")
                        continue
                    
                    # ë§ˆí¬ë‹¤ìš´ í—¤ë”© ì²˜ë¦¬
                    if line_stripped.startswith('###'):
                        doc.add_heading(line_stripped.replace('###', '').strip(), level=3)
                    elif line_stripped.startswith('##'):
                        doc.add_heading(line_stripped.replace('##', '').strip(), level=2)
                    elif line_stripped.startswith('#'):
                        doc.add_heading(line_stripped.replace('#', '').strip(), level=2)
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ë˜ëŠ” í‘œ ì²˜ë¦¬
                        paragraph = doc.add_paragraph()
                        paragraph.add_run(line_stripped)
            else:
                # ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° ì•Œë¦¼ ì¶”ê°€
                doc.add_paragraph(f"[{title}] ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì„¹ì…˜ ê°„ í˜ì´ì§€ ë¸Œë ˆì´í¬ (ë§ˆì§€ë§‰ ì„¹ì…˜ ì œì™¸)
            sections_list = list(sections.items())
            if (title, content) != sections_list[-1]:
                doc.add_page_break()
        
        doc.save(filename)
        return True
    except Exception as e:
        st.error(f"Word íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

# PDF íŒŒì¼ ì €ì¥ (ê°œì„ ëœ ë²„ì „) - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
def save_to_pdf(filename, **sections):
    try:
        # í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹œë„
        font_name = 'Helvetica'  # ê¸°ë³¸ í°íŠ¸
        try:
            # Windows í•œê¸€ í°íŠ¸ ì‹œë„
            font_paths = [
                'C:/Windows/Fonts/malgun.ttf',
                'C:/Windows/Fonts/batang.ttf',
                'C:/Windows/Fonts/gulim.ttf'
            ]
            for font_path in font_paths:
                if os.path.exists(font_path):
                    pdfmetrics.registerFont(TTFont('Korean', font_path))
                    font_name = 'Korean'
                    break
        except Exception as e:
            st.warning(f"í•œê¸€ í°íŠ¸ ë¡œë”© ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©: {e}")
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        styles = getSampleStyleSheet()
        
        korean_normal = ParagraphStyle(
            'KoreanNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            leading=16,
            leftIndent=0,
            rightIndent=0,
            spaceAfter=6
        )
        
        korean_heading = ParagraphStyle(
            'KoreanHeading',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=16,
            leading=20,
            spaceBefore=12,
            spaceAfter=12,
            leftIndent=0
        )
        
        story = []
        
        # ë‚´ìš© ì²˜ë¦¬
        for title, content in sections.items():
            # ì œëª© ì¶”ê°€
            story.append(Paragraph(f"<b>{title}</b>", korean_heading))
            story.append(Spacer(1, 0.2*inch))
            
            # ë‚´ìš© ì²˜ë¦¬
            if content and content.strip():
                # ì¤„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                lines = content.split('\n')
                for line in lines:
                    line_clean = line.strip()
                    
                    if line_clean:
                        # HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                        line_escaped = (line_clean
                                       .replace('&', '&amp;')
                                       .replace('<', '&lt;')
                                       .replace('>', '&gt;')
                                       .replace('"', '&quot;'))
                        
                        try:
                            # ë§ˆí¬ë‹¤ìš´ í—¤ë”© ì²˜ë¦¬
                            if line_escaped.startswith('###'):
                                heading_text = line_escaped.replace('###', '').strip()
                                story.append(Paragraph(f"<b>{heading_text}</b>", korean_normal))
                            elif line_escaped.startswith('##'):
                                heading_text = line_escaped.replace('##', '').strip()
                                story.append(Paragraph(f"<b>{heading_text}</b>", korean_normal))
                            elif line_escaped.startswith('#'):
                                heading_text = line_escaped.replace('#', '').strip()
                                story.append(Paragraph(f"<b>{heading_text}</b>", korean_normal))
                            else:
                                # ì¼ë°˜ í…ìŠ¤íŠ¸
                                story.append(Paragraph(line_escaped, korean_normal))
                            
                            story.append(Spacer(1, 3))
                            
                        except Exception as e:
                            # í°íŠ¸ ë¬¸ì œ ì‹œ ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©
                            try:
                                story.append(Paragraph(line_escaped, styles['Normal']))
                                story.append(Spacer(1, 3))
                            except:
                                # ê·¸ë˜ë„ ì•ˆ ë˜ë©´ ê±´ë„ˆë›°ê¸°
                                continue
            
            # ì„¹ì…˜ ê°„ í˜ì´ì§€ ë¸Œë ˆì´í¬
            sections_list = list(sections.items())
            if (title, content) != sections_list[-1]:
                story.append(PageBreak())
        
        doc = SimpleDocTemplate(filename, pagesize=A4)
        doc.build(story)
        return True
    except Exception as e:
        st.warning(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. Word íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        return False

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ ì¶”ê°€
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        "images": [],
        "base64_images": [],
        "page_number": 1,
        "start_page": 1,
        "end_page": 1,
        "analysis_results": {},
        "last_analysis_done": False,
        "include_images": False,
        "temp_files": [],  # ì„ì‹œ íŒŒì¼ ì¶”ì ìš©
        "api_key_validated": False,
        "client": None
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

# ë©”ì¸ ì•±
def main():
    st.set_page_config(layout="wide", page_title="PDF Vision ë²ˆì—­/ìš”ì•½ í”„ë¡œê·¸ë¨")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()

    with st.sidebar:
        st.title("ğŸ“„ PDF Vision ë²ˆì—­/ìš”ì•½")
        st.markdown("*GPT Visionìœ¼ë¡œ ì´ë¯¸ì§€ ì§ì ‘ ë¶„ì„*")
        
        # API í‚¤ ì…ë ¥ ë° ê²€ì¦
        openai_api_key = st.text_input("OpenAI API Key", type="password", 
                                      help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        st.write("[OpenAI API Key ë°›ê¸°](https://platform.openai.com/account/api-keys)")
        
        # API í‚¤ ê²€ì¦
        if openai_api_key and (not st.session_state.api_key_validated or 
                              st.session_state.get('last_api_key', '') != openai_api_key):
            with st.spinner("API í‚¤ í™•ì¸ ì¤‘..."):
                client, is_valid, error_msg = validate_openai_api_key(openai_api_key)
                if is_valid:
                    st.session_state.client = client
                    st.session_state.api_key_validated = True
                    st.session_state.last_api_key = openai_api_key
                    st.success("âœ… API í‚¤ í™•ì¸ë¨")
                else:
                    st.session_state.client = None
                    st.session_state.api_key_validated = False
                    st.error(f"âŒ {error_msg}")

        # ëª¨ë¸ ì„ íƒ
        model_option = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["gpt-4o-mini", "gpt-4o", "gpt-4o-2024-11-20", "gpt-5-mini", "gpt-5"],
            index=0,
            help="GPT-5 ê³„ì—´ì€ ìµœê³  í’ˆì§ˆì´ì§€ë§Œ ë” ë§ì€ í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. GPT-4oëŠ” ê· í˜•ì¡íŒ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
        )

        pdf_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])
        mode = st.radio("í˜ì´ì§€ ì„ íƒ", ["ë‹¨ì¼ í˜ì´ì§€", "í˜ì´ì§€ ë²”ìœ„", "ì „ì²´ ë¬¸ì„œ"])

        client = st.session_state.client

        # PDF íŒŒì¼ ì²˜ë¦¬
        if pdf_file:
            # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            current_file_hash = hash(pdf_file.getvalue())
            if st.session_state.get('last_file_hash') != current_file_hash:
                # ì´ì „ ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
                cleanup_temp_files(st.session_state.temp_files)
                st.session_state.temp_files = []
                
                pdf_data = pdf_file.read()
                with st.spinner("PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘..."):
                    st.session_state.images, st.session_state.base64_images = convert_pdf_to_base64_images(pdf_data)
                
                # ì´ë¯¸ì§€ ê²½ë¡œë“¤ì„ ì„ì‹œ íŒŒì¼ ëª©ë¡ì— ì¶”ê°€
                st.session_state.temp_files.extend(st.session_state.images)
                st.session_state.last_file_hash = current_file_hash
                
                # ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
                st.session_state.analysis_results = {}
                st.session_state.last_analysis_done = False
            
            total_pages = len(st.session_state.images)
            if total_pages > 0:
                st.success(f"ì´ {total_pages}í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")

                if mode == "ë‹¨ì¼ í˜ì´ì§€":
                    st.session_state.page_number = st.number_input(
                        "í˜ì´ì§€ ë²ˆí˜¸", 1, total_pages, st.session_state.page_number
                    )
                elif mode == "í˜ì´ì§€ ë²”ìœ„":
                    st.session_state.start_page = st.number_input(
                        "ì‹œì‘ í˜ì´ì§€", 1, total_pages, st.session_state.start_page
                    )
                    st.session_state.end_page = st.number_input(
                        "ë í˜ì´ì§€", st.session_state.start_page, total_pages,
                        min(st.session_state.end_page, total_pages)
                    )
            else:
                st.error("PDF ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # ë©”ì¸ ì½˜í…ì¸ 
    if pdf_file and st.session_state.images:
        left, right = st.columns([1, 1])
        
        with left:
            st.subheader("ğŸ“– ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°")
            try:
                if mode == "ë‹¨ì¼ í˜ì´ì§€":
                    if 0 <= st.session_state.page_number-1 < len(st.session_state.images):
                        st.image(st.session_state.images[st.session_state.page_number-1], 
                                caption=f"í˜ì´ì§€ {st.session_state.page_number}")
                elif mode == "í˜ì´ì§€ ë²”ìœ„":
                    for i in range(st.session_state.start_page-1, min(st.session_state.end_page, len(st.session_state.images))):
                        if i < len(st.session_state.images):
                            st.image(st.session_state.images[i], caption=f"í˜ì´ì§€ {i+1}")
                else:
                    # ì „ì²´ ë¬¸ì„œì˜ ê²½ìš° ì²˜ìŒ 5í˜ì´ì§€ë§Œ ë¯¸ë¦¬ë³´ê¸°
                    preview_count = min(5, len(st.session_state.images))
                    for i in range(preview_count):
                        st.image(st.session_state.images[i], caption=f"í˜ì´ì§€ {i+1}")
                    if len(st.session_state.images) > 5:
                        st.info(f"ë¯¸ë¦¬ë³´ê¸°ëŠ” ì²˜ìŒ 5í˜ì´ì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤. (ì „ì²´ {len(st.session_state.images)}í˜ì´ì§€)")
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")

        with right:
            st.subheader("ğŸ¤– AI ë¶„ì„ ë° ì²˜ë¦¬")
            
            if not st.session_state.api_key_validated:
                st.warning("ë¨¼ì € ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ì²˜ë¦¬ ì˜µì…˜
                col1, col2 = st.columns(2)
                with col1:
                    do_summary = st.checkbox("ğŸ“‹ ìš”ì•½í•˜ê¸°", value=True)
                with col2:
                    do_translation = st.checkbox("ğŸŒ ë²ˆì—­í•˜ê¸°", value=True)
                
                # ì¶”ê°€ ì˜µì…˜
                with st.expander("ğŸ”§ ê³ ê¸‰ ì„¤ì •"):
                    include_images = st.checkbox("ğŸ“¸ ê²°ê³¼ì— ì›ë³¸ ì´ë¯¸ì§€ í¬í•¨", value=False, 
                                               help="ë²ˆì—­/ìš”ì•½ ê²°ê³¼ì™€ í•¨ê»˜ ì›ë³¸ ì´ë¯¸ì§€ë„ í‘œì‹œí•©ë‹ˆë‹¤")
                    
                    # ëª¨ë¸ë³„ ê¶Œì¥ í† í° ìˆ˜ ì„¤ì •
                    if model_option in ["gpt-5", "gpt-5-mini"]:
                        default_tokens = 12000
                        max_tokens_limit = 32000
                        token_help = "GPT-5 ê³„ì—´ì€ ë” ë§ì€ í† í°ì´ í•„ìš”í•˜ë©°, ë” ê¸´ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    else:
                        default_tokens = 8000
                        max_tokens_limit = 16000
                        token_help = "GPT-4o ê³„ì—´ì˜ ê¶Œì¥ í† í° ìˆ˜ì…ë‹ˆë‹¤."
                    
                    max_tokens = st.slider("ìµœëŒ€ í† í° ìˆ˜", 2000, max_tokens_limit, default_tokens, 
                                         help=token_help)
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ì‹ ì„ íƒ
                    image_detail = st.selectbox(
                        "ì´ë¯¸ì§€ í•´ìƒë„",
                        ["high", "low"],
                        index=0,
                        help="high: ê³ í™”ì§ˆ ë¶„ì„ (í† í° ë§ì´ ì‚¬ìš©), low: ì €í™”ì§ˆ ë¶„ì„ (í† í° ì ˆì•½)"
                    )
                    
                    # í˜ì´ì§€ ë¶„í•  ì²˜ë¦¬ ì˜µì…˜
                    process_separately = st.checkbox(
                        "í˜ì´ì§€ë³„ ê°œë³„ ì²˜ë¦¬ (ë¬¸ë§¥ ì—°ê²°)", 
                        value=True,
                        help="ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë˜, í˜ì´ì§€ ê°„ ë¬¸ë§¥ì„ ì—°ê²°í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬ (ê¶Œì¥)"
                    )
                    
                    # GPT-5 ì‚¬ìš© ì‹œ ì¶”ê°€ ì•ˆë‚´
                    if model_option in ["gpt-5", "gpt-5-mini"]:
                        st.info("ğŸ’¡ GPT-5 ëª¨ë¸ ì‚¬ìš© ì‹œ ë” ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­/ìš”ì•½ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, ì²˜ë¦¬ ì‹œê°„ê³¼ ë¹„ìš©ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # include_images ê°’ì„ ì„¸ì…˜ì— ì €ì¥
                    st.session_state.include_images = include_images

                if not (do_summary or do_translation):
                    st.warning("ìš”ì•½ ë˜ëŠ” ë²ˆì—­ ì¤‘ í•˜ë‚˜ëŠ” ì„ íƒí•´ì£¼ì„¸ìš”.")
                
                # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
                analysis_disabled = not (do_summary or do_translation) or not st.session_state.api_key_validated
                if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘", disabled=analysis_disabled):
                    if not st.session_state.base64_images:
                        st.error("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ì„ íƒëœ í˜ì´ì§€ì˜ ì´ë¯¸ì§€ë§Œ ì¶”ì¶œ
                        try:
                            if mode == "ë‹¨ì¼ í˜ì´ì§€":
                                if 0 <= st.session_state.page_number-1 < len(st.session_state.base64_images):
                                    selected_images = [st.session_state.base64_images[st.session_state.page_number-1]]
                                else:
                                    st.error("ì„ íƒí•œ í˜ì´ì§€ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
                                    selected_images = []
                            elif mode == "í˜ì´ì§€ ë²”ìœ„":
                                start_idx = max(0, st.session_state.start_page-1)
                                end_idx = min(len(st.session_state.base64_images), st.session_state.end_page)
                                selected_images = st.session_state.base64_images[start_idx:end_idx]
                            else:
                                selected_images = st.session_state.base64_images

                            if not selected_images:
                                st.error("ì„ íƒëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                results = {}
                                
                                # ìš”ì•½ ì²˜ë¦¬
                                if do_summary:
                                    with st.spinner("ğŸ“‹ ë¬¸ì„œ ìš”ì•½ ì¤‘..."):
                                        summary = analyze_images_with_gpt(
                                            client=client, 
                                            base64_images=selected_images, 
                                            prompt_type="summary", 
                                            model=model_option, 
                                            max_tokens=max_tokens, 
                                            image_detail=image_detail, 
                                            process_separately=process_separately
                                        )
                                        if summary:
                                            results["ìš”ì•½ ê²°ê³¼"] = summary

                                # ë²ˆì—­ ì²˜ë¦¬
                                if do_translation:
                                    with st.spinner("ğŸŒ ë¬¸ì„œ ë²ˆì—­ ì¤‘..."):
                                        translation = analyze_images_with_gpt(
                                            client=client,
                                            base64_images=selected_images, 
                                            prompt_type="translation", 
                                            model=model_option,
                                            max_tokens=max_tokens, 
                                            image_detail=image_detail, 
                                            process_separately=process_separately
                                        )
                                        if translation:
                                            results["ë²ˆì—­ ê²°ê³¼"] = translation

                                # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                if results:
                                    st.session_state.analysis_results = results
                                    st.session_state.last_analysis_done = True
                                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                                else:
                                    st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        
                        except Exception as e:
                            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    if st.session_state.last_analysis_done and st.session_state.analysis_results:
        results = st.session_state.analysis_results
        
        st.markdown("---")
        
        # ìš”ì•½ ê²°ê³¼ í‘œì‹œ
        if "ìš”ì•½ ê²°ê³¼" in results:
            st.subheader("ğŸ“‹ ìš”ì•½ ê²°ê³¼")
            st.markdown(results["ìš”ì•½ ê²°ê³¼"])
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬í•¨ ì˜µì…˜ (ìš”ì•½ìš©)
            if st.session_state.get('include_images', False):
                st.subheader("ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ (ìš”ì•½)")
                try:
                    if mode == "ë‹¨ì¼ í˜ì´ì§€":
                        if 0 <= st.session_state.page_number-1 < len(st.session_state.images):
                            st.image(st.session_state.images[st.session_state.page_number-1], 
                                    caption=f"ì›ë³¸ í˜ì´ì§€ {st.session_state.page_number}")
                    elif mode == "í˜ì´ì§€ ë²”ìœ„":
                        for i in range(st.session_state.start_page-1, min(st.session_state.end_page, len(st.session_state.images))):
                            if i < len(st.session_state.images):
                                st.image(st.session_state.images[i], caption=f"ì›ë³¸ í˜ì´ì§€ {i+1}")
                    else:
                        for i, img in enumerate(st.session_state.images):
                            st.image(img, caption=f"ì›ë³¸ í˜ì´ì§€ {i+1}")
                except Exception as e:
                    st.error(f"ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")

        # ë²ˆì—­ ê²°ê³¼ í‘œì‹œ
        if "ë²ˆì—­ ê²°ê³¼" in results:
            st.subheader("ğŸŒ ë²ˆì—­ ê²°ê³¼")
            st.markdown(results["ë²ˆì—­ ê²°ê³¼"])
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬í•¨ ì˜µì…˜ (ë²ˆì—­ìš© - ìš”ì•½ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
            if st.session_state.get('include_images', False) and "ìš”ì•½ ê²°ê³¼" not in results:
                st.subheader("ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ (ë²ˆì—­)")
                try:
                    if mode == "ë‹¨ì¼ í˜ì´ì§€":
                        if 0 <= st.session_state.page_number-1 < len(st.session_state.images):
                            st.image(st.session_state.images[st.session_state.page_number-1], 
                                    caption=f"ì›ë³¸ í˜ì´ì§€ {st.session_state.page_number}")
                    elif mode == "í˜ì´ì§€ ë²”ìœ„":
                        for i in range(st.session_state.start_page-1, min(st.session_state.end_page, len(st.session_state.images))):
                            if i < len(st.session_state.images):
                                st.image(st.session_state.images[i], caption=f"ì›ë³¸ í˜ì´ì§€ {i+1}")
                    else:
                        for i, img in enumerate(st.session_state.images):
                            st.image(img, caption=f"ì›ë³¸ í˜ì´ì§€ {i+1}")
                except Exception as e:
                    st.error(f"ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        temp_files_for_cleanup = []
        
        try:
            # Word íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp_docx:
                if save_to_word(tmp_docx.name, **results):
                    tmp_docx_path = tmp_docx.name
                    temp_files_for_cleanup.append(tmp_docx_path)
                else:
                    tmp_docx_path = None

            # PDF íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_pdf:
                if save_to_pdf(tmp_pdf.name, **results):
                    tmp_pdf_path = tmp_pdf.name
                    temp_files_for_cleanup.append(tmp_pdf_path)
                else:
                    tmp_pdf_path = None
                
            # QMD íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix=".qmd") as tmp_qmd:
                if save_to_qmd(tmp_qmd.name, **results):
                    tmp_qmd_path = tmp_qmd.name
                    temp_files_for_cleanup.append(tmp_qmd_path)
                else:
                    tmp_qmd_path = None

            col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
            
            with col1:
                if tmp_docx_path:
                    try:
                        with open(tmp_docx_path, "rb") as f:
                            docx_data = f.read()
                            st.download_button(
                                "ğŸ“„ Word ë‹¤ìš´ë¡œë“œ", 
                                docx_data, 
                                file_name="pdf_analysis_result.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                    except Exception as e:
                        st.error(f"Word íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                else:
                    st.error("Word íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    
            with col2:
                if tmp_pdf_path:
                    try:
                        with open(tmp_pdf_path, "rb") as f:
                            pdf_data = f.read()
                            st.download_button(
                                "ğŸ“• PDF ë‹¤ìš´ë¡œë“œ", 
                                pdf_data, 
                                file_name="pdf_analysis_result.pdf",
                                mime="application/pdf"
                            )
                    except Exception as e:
                        st.error(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                else:
                    st.warning("PDF íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    
            with col3:
                if tmp_qmd_path:
                    try:
                        with open(tmp_qmd_path, "rb") as f:
                            qmd_data = f.read()
                            st.download_button(
                                "ğŸ“ QMD ë‹¤ìš´ë¡œë“œ", 
                                qmd_data, 
                                file_name="pdf_analysis_result.qmd",
                                mime="text/plain"
                            )
                    except Exception as e:
                        st.error(f"QMD íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                else:
                    st.error("QMD íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    
            with col4:
                if st.button("ğŸ—‘ï¸ ê²°ê³¼ ì§€ìš°ê¸°"):
                    st.session_state.analysis_results = {}
                    st.session_state.last_analysis_done = False
                    st.rerun()

        except Exception as e:
            st.error(f"íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleanup_temp_files(temp_files_for_cleanup)

    # ì‚¬ìš©ë²• ì•ˆë‚´
    if not pdf_file:
        st.markdown("""
        ## ğŸ¯ ì‚¬ìš©ë²•
        
        1. **OpenAI API Key ì…ë ¥**: ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
        2. **PDF ì—…ë¡œë“œ**: ë²ˆì—­/ìš”ì•½í•˜ê³  ì‹¶ì€ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        3. **í˜ì´ì§€ ì„ íƒ**: ì „ì²´ ë¬¸ì„œ ë˜ëŠ” íŠ¹ì • í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”
        4. **ì²˜ë¦¬ ì˜µì…˜ ì„ íƒ**: ìš”ì•½, ë²ˆì—­ ë˜ëŠ” ë‘˜ ë‹¤ ì„ íƒí•˜ì„¸ìš”
        5. **AI ë¶„ì„ ì‹œì‘**: ë²„íŠ¼ì„ ëˆŒëŸ¬ GPT Visionìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”
        
        ## âœ¨ íŠ¹ì§•
        
        - **OCR ë¶ˆí•„ìš”**: GPT Visionì´ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì½ì–´ ë” ì •í™•í•¨
        - **ì‹œê°ì  ìš”ì†Œ ë¶„ì„**: í‘œ, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨ë„ í•¨ê»˜ ë¶„ì„
        - **ì»¨í…ìŠ¤íŠ¸ ì´í•´**: ë¬¸ì„œ êµ¬ì¡°ì™€ ë ˆì´ì•„ì›ƒì„ ê³ ë ¤í•œ ë¶„ì„
        - **ê³ í’ˆì§ˆ ë²ˆì—­/ìš”ì•½**: GPT-5ì˜ ìµœê³ ê¸‰ ì–¸ì–´ ëŠ¥ë ¥ ë˜ëŠ” GPT-4oì˜ ê· í˜•ì¡íŒ ì„±ëŠ¥ í™œìš©
        - **ë¬¸ë§¥ ì—°ê²°**: í˜ì´ì§€ ê°„ ì´ì–´ì§€ëŠ” ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²° ì²˜ë¦¬
        - **ë‹¤ì–‘í•œ ëª¨ë¸**: GPT-4oë¶€í„° ìµœì‹  GPT-5ê¹Œì§€ ë‹¤ì–‘í•œ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
        - **ì•ˆì •ì„± í–¥ìƒ**: ì—ëŸ¬ ì²˜ë¦¬ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 
        """)

# ì•± ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…
@st.cache_resource
def cleanup_on_exit():
    """ì•± ì¢…ë£Œ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    def cleanup():
        if 'temp_files' in st.session_state:
            cleanup_temp_files(st.session_state.temp_files)
    
    import atexit
    atexit.register(cleanup)
    return True

if __name__ == "__main__":
    cleanup_on_exit()
    main()
